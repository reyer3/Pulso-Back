# ğŸš€ Pulso-Back: API + ETL Backend (CLEAN ARCHITECTURE)

**API + ETL Backend Simplificado para Dashboard Cobranzas TelefÃ³nica**

FastAPI + Redis + PostgreSQL + BigQuery con ETL Incremental Puro

## ğŸ—ï¸ Arquitectura Simplificada

```
BigQuery â†’ ETL Pipeline â†’ PostgreSQL â†’ FastAPI â†’ React Dashboard
                â†“
        Watermarks Simples (solo Ãºltima fecha)
```

## ğŸ¯ Stack TecnolÃ³gico

- **FastAPI** - API REST con OpenAPI automÃ¡tico
- **Redis** - Cache de consultas frecuentes
- **PostgreSQL (asyncpg)** - Storage para ETL
- **BigQuery** - Source of truth
- **ETL Incremental** - Solo datos nuevos sin lÃ³gicas complejas

## ğŸš€ Quick Start

```bash
# 1. Clonar repositorio
git clone https://github.com/reyer3/Pulso-Back.git
cd Pulso-Back

# 2. Configurar variables de entorno
cp .env.production.example .env
# Editar .env con tus credenciales

# 3. Aplicar migraciones
yoyo apply

# 4. Ejecutar ETL
python etl/main.py

# 5. Verificar API
curl http://localhost:8000/health
```

## ğŸ“ Estructura Clean Architecture

```
pulso-back/
â”œâ”€â”€ app/                         # FastAPI Application  
â”‚   â”œâ”€â”€ api/v1/                 # API endpoints
â”‚   â”œâ”€â”€ core/                   # Configuration
â”‚   â”œâ”€â”€ models/                 # Pydantic models
â”‚   â”œâ”€â”€ repositories/           # Data access layer
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â””â”€â”€ utils/                  # Utilities
â”œâ”€â”€ etl/                        # ETL Clean Architecture
â”‚   â”œâ”€â”€ main.py                 # ğŸ†• Standard entry point
â”‚   â”œâ”€â”€ pipelines/              
â”‚   â”‚   â””â”€â”€ simple_incremental_pipeline.py  # Core pipeline logic
â”‚   â”œâ”€â”€ extractors/             # BigQuery extraction
â”‚   â”œâ”€â”€ loaders/                # PostgreSQL loading
â”‚   â”œâ”€â”€ watermarks.py           # Simple watermark management
â”‚   â”œâ”€â”€ config.py               # Table configuration
â”‚   â””â”€â”€ sql/                    # SQL queries
â”œâ”€â”€ scripts/                    # Deployment & utilities
â””â”€â”€ tests/                      # Testing
```

## ğŸ”„ ETL Commands

### **ğŸš€ Standard Entry Point (Recomendado):**

```bash
# Procesar todas las tablas
python etl/main.py

# Tablas especÃ­ficas
python etl/main.py --tables asignaciones trandeuda pagos

# Con logging detallado
python etl/main.py --log-level DEBUG

# Ver plan de ejecuciÃ³n (dry run)
python etl/main.py --dry-run

# Listar tablas disponibles
python etl/main.py --list-tables

# Ayuda completa
python etl/main.py --help
```

### **ğŸ”„ Legacy Entry Point (Compatibilidad):**
```bash
# Wrapper de compatibilidad (redirige a main.py)
python etl/simple_incremental_etl.py
```

### **âš™ï¸ Comandos de ProducciÃ³n:**

```bash
# Cron job (cada 3 horas)
0 */3 * * * cd /app && python etl/main.py >> /var/log/etl.log 2>&1

# Docker
docker run pulso-back python etl/main.py --tables asignaciones

# Kubernetes CronJob
kubectl apply -f k8s/etl-cronjob.yaml
```

## ğŸ¯ CÃ³mo Funciona el ETL

### **Pipeline Flow:**
1. **Lee watermarks**: Ãšltima fecha extraÃ­da por tabla
2. **Extrae incremental**: `WHERE fecha > watermark` desde BigQuery
3. **Carga datos**: UPSERT a PostgreSQL con manejo de duplicados
4. **Actualiza watermark**: Nueva fecha mÃ¡xima extraÃ­da

### **Ejemplo de EjecuciÃ³n:**
```bash
$ python etl/main.py --tables asignaciones --log-level INFO

ğŸš€ SIMPLE INCREMENTAL PIPELINE
================================================================================
ğŸ“Š Tables to process: 1
ğŸ“‹ Tables: asignaciones

ğŸ“‹ [1/1] Processing: asignaciones
ğŸ†• asignaciones: primera extracciÃ³n (Ãºltimos 30 dÃ­as)
ğŸ” Extracting asignaciones...
âœ… asignaciones: extracted 15,432 records total
âœ… asignaciones: loaded 15,432 records
âœ… asignaciones: 15,432 records in 23.45s

ğŸ“Š PIPELINE EXECUTION RESULTS
================================================================================
âœ… Successful tables: 1/1
âŒ Failed tables: 0
ğŸ“Š Total extracted: 15,432
ğŸ“Š Total loaded: 15,432
â±ï¸ Total duration: 23.45s

ğŸ‰ ETL Pipeline completed successfully!
```

## ğŸ“Š Watermarks Simples

### **Monitoreo:**
```sql
-- Ver estado actual de watermarks
SELECT table_name, last_extracted_at, updated_at 
FROM etl_watermarks_simple 
ORDER BY updated_at DESC;
```

### **Operaciones Manuales:**
```sql
-- Reset watermark para re-extraer datos
UPDATE etl_watermarks_simple 
SET last_extracted_at = '2025-07-01 00:00:00+00'
WHERE table_name = 'asignaciones';

-- Eliminar watermark (fuerza extracciÃ³n completa)
DELETE FROM etl_watermarks_simple 
WHERE table_name = 'asignaciones';
```

### **Health Check:**
```bash
python -c "
import asyncio
from etl.watermarks import get_watermark_status
print(asyncio.run(get_watermark_status()))
"
```

## ğŸ“‹ API Endpoints

```
GET  /api/v1/dashboard     # Dashboard principal
GET  /api/v1/evolution     # Evolutivos por dÃ­a
GET  /api/v1/assignment    # AnÃ¡lisis de asignaciÃ³n
GET  /api/v1/health        # Health check
GET  /docs                 # OpenAPI docs
```

## ğŸ”§ ConfiguraciÃ³n de Tablas

Las tablas se configuran en `etl/config.py`:

```python
"asignaciones": ExtractionConfig(
    table_name="asignaciones",
    table_type=TableType.RAW,
    source_table="batch_P3fV4dWNeMkN5RJMhV8e_asignacion",
    incremental_column="creado_el",           # Columna para filtrado incremental
    primary_key=["cod_luna", "cuenta"],      # Keys para UPSERT
    batch_size=50000                         # TamaÃ±o de lote
)
```

## ğŸ³ Docker & Production

### **Variables de Entorno:**
```bash
# Database
POSTGRES_HOST=prod-db.company.com
POSTGRES_PASSWORD=secure_password
POSTGRES_SSLMODE=require

# BigQuery
BIGQUERY_PROJECT_ID=mibot-222814
BIGQUERY_CREDENTIALS_PATH=/app/credentials.json

# ETL
ETL_DEFAULT_BATCH_SIZE=10000
```

### **Docker Compose:**
```yaml
services:
  etl:
    image: pulso-back:latest
    environment:
      - POSTGRES_HOST=db
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    command: ["python", "etl/main.py"]
```

### **Kubernetes CronJob:**
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pulso-etl
spec:
  schedule: "0 */3 * * *"  # Cada 3 horas
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: etl
            image: pulso-back:latest
            command: ["python", "etl/main.py"]
            env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: password
```

## ğŸ§ª Testing

```bash
# Test del pipeline
python etl/main.py --dry-run

# Test de tablas especÃ­ficas  
python etl/main.py --tables calendario --log-level DEBUG

# Unit tests
pytest tests/unit/

# Integration tests
pytest tests/integration/
```

## ğŸ¯ Ventajas de la Nueva Arquitectura

### **âœ… Clean Architecture:**
- **Entry point limpio**: Solo maneja CLI y orquestaciÃ³n
- **Pipeline separado**: LÃ³gica de negocio aislada y testeable
- **Watermarks modulares**: Reutilizables en otros scripts
- **ConfiguraciÃ³n centralizada**: Una sola fuente de verdad

### **âœ… Mantenibilidad:**
- **1 entry point**: `etl/main.py` (estÃ¡ndar)
- **1 pipeline**: `SimpleIncrementalPipeline` (core logic)
- **SeparaciÃ³n clara**: CLI vs Business Logic
- **FÃ¡cil testing**: Cada componente es testeable por separado

### **âœ… Operacional:**
- **CLI robusto**: Validaciones, dry-run, help completo
- **Logging estructurado**: Levels apropiados por ambiente
- **Exit codes**: IntegraciÃ³n con schedulers y CI/CD
- **Compatibilidad**: Entry point legacy para transiciÃ³n

### **âœ… Performance:**
- **ETL incremental puro**: Solo datos nuevos
- **Watermarks optimizados**: Batch operations, validaciones
- **UPSERT eficiente**: Manejo inteligente de duplicados
- **ConfiguraciÃ³n por tabla**: Batch sizes optimizados

---

## ğŸ”„ MigraciÃ³n desde VersiÃ³n Anterior

### **Old Way (Deprecated):**
```bash
python etl/simple_incremental_etl.py --tables asignaciones
```

### **New Way (Recommended):**
```bash
python etl/main.py --tables asignaciones
```

### **Compatibility:**
- El entry point anterior sigue funcionando (muestra warning)
- Todos los argumentos se mapean automÃ¡ticamente
- Misma funcionalidad, mejor arquitectura

---

**Refactorizado por Ricardo Reyes para Onbotgo**

> ğŸ¯ **FilosofÃ­a**: Clean Architecture + ETL incremental puro + Entry points estÃ¡ndar
