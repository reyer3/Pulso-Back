# ğŸš€ Pulso-Back: API + ETL Backend

**API + ETL Backend para Dashboard Cobranzas TelefÃ³nica**

FastAPI + Redis + PostgreSQL + BigQuery con patrones KISS y DRY

## ğŸ—ï¸ Arquitectura

```
BigQuery â†’ ETL Pipeline â†’ Redis Cache â†’ FastAPI â†’ React Dashboard
                â†“
            PostgreSQL (persistencia)
```

## ğŸ¯ Stack TecnolÃ³gico

- **FastAPI** - API REST con OpenAPI automÃ¡tico
- **Redis** - Cache de consultas frecuentes
- **PostgreSQL (asyncpg)** - Storage para ETL (acceso con `asyncpg`)
- **BigQuery (`google-cloud-bigquery`)** - Source of truth (acceso directo con cliente oficial)
- **Docker** - ContainerizaciÃ³n
- **Traefik** - Reverse proxy
- **Celery** - Job scheduling
- **Prometheus** - Monitoring

## ğŸ“Š Patrones de DiseÃ±o

- **Repository Pattern** - AbstracciÃ³n de acceso a datos
- **Service Pattern** - LÃ³gica de negocio encapsulada
- **Factory Pattern** - CreaciÃ³n de objetos
- **Dependency Injection** - InversiÃ³n de control
- **Strategy Pattern** - Algoritmos intercambiables
- **Cache-Aside Pattern** - Estrategia de cache
- **Template Method Pattern** - Pipelines ETL

## ğŸš€ Quick Start

```bash
# 1. Clonar repositorio
git clone https://github.com/reyer3/Pulso-Back.git
cd Pulso-Back

# 2. Configurar ambiente
cp .env.example .env
# Editar .env con tus credenciales

# 3. Levantar con Docker
docker-compose up -d

# 4. Verificar API
curl http://localhost:8000/health
```

## ğŸ“ Estructura del Proyecto

```
pulso-back/
â”œâ”€â”€ app/                    # FastAPI Application  
â”‚   â”œâ”€â”€ api/v1/            # API endpoints
â”‚   â”œâ”€â”€ core/              # Configuration
â”‚   â”œâ”€â”€ models/            # Pydantic models
â”‚   â”œâ”€â”€ repositories/      # Data access layer
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â””â”€â”€ utils/             # Utilities
â”œâ”€â”€ etl/                   # ETL Pipeline
â”‚   â”œâ”€â”€ extractors/        # Data extraction
â”‚   â”œâ”€â”€ transformers/      # Data transformation  
â”‚   â”œâ”€â”€ loaders/           # Data loading
â”‚   â””â”€â”€ pipelines/         # ETL orchestration
â”œâ”€â”€ docker/                # Docker configs
â”œâ”€â”€ scripts/               # Deployment scripts
â””â”€â”€ tests/                 # Testing
```

## ğŸ”„ ETL Pipeline

**Refresh cada 3 horas:**
1. **Extract** - BigQuery views
2. **Transform** - Agregaciones y cÃ¡lculos
3. **Load** - Redis cache + PostgreSQL

## ğŸ“‹ API Endpoints

```
GET  /api/v1/dashboard     # Dashboard principal
GET  /api/v1/evolution     # Evolutivos por dÃ­a
GET  /api/v1/assignment    # AnÃ¡lisis de asignaciÃ³n
GET  /api/v1/health        # Health check
GET  /docs                 # OpenAPI docs
```

## ğŸ³ Docker & Traefik

Integrado con tu stack existente:
- **Traefik** - Routing automÃ¡tico
- **Redis** - Reutiliza tu instancia
- **PostgreSQL** - Nuevo servicio (usando `asyncpg`, no `psycopg2`)

**Nota importante sobre dependencias de base de datos:** El backend solo usa BigQuery (via `google-cloud-bigquery`) y PostgreSQL (via `asyncpg`). No hay dependencia de `psycopg2` ni de SQLAlchemy para el acceso en tiempo de ejecuciÃ³n a PostgreSQL. SQLAlchemy puede seguir usÃ¡ndose para migraciones con Alembic si es necesario.

## ğŸ“Š Monitoring

- **Prometheus** - MÃ©tricas
- **Grafana** - Dashboards
- **Logs** - Structured logging

## ğŸ§ª Testing

```bash
# Unit tests
pytest tests/unit/

# Integration tests  
pytest tests/integration/

# Coverage
pytest --cov=app
```

## ğŸš€ Deploy

```bash
# Production deploy
./scripts/deploy.sh production

# Staging deploy
./scripts/deploy.sh staging
```

---
**Creado por Ricky para TelefÃ³nica Cobranzas**