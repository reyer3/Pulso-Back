# etl/pipelines/raw_data_pipeline_creado_el_integration.md

# üéØ GU√çA DE INTEGRACI√ìN: Filtrado por creado_el en HybridRawDataPipeline

## üìã Resumen de Archivos Creados

1. **raw_data_pipeline_creado_el_enum.py** - Nueva estrategia enum
2. **raw_data_pipeline_creado_el_query.py** - M√©todo constructor de queries  
3. **raw_data_pipeline_creado_el_single.py** - M√©todo para una tabla
4. **raw_data_pipeline_creado_el_multiple.py** - M√©todo para m√∫ltiples tablas

## üîß Pasos de Integraci√≥n Manual

### PASO 1: Actualizar ExtractionStrategy (l√≠nea ~35)
```python
class ExtractionStrategy(str, Enum):
    """Estrategias de extracci√≥n disponibles"""
    CALENDAR_DRIVEN = "calendar_driven"  # Guiado por fechas de campa√±a
    WATERMARK_DRIVEN = "watermark_driven"  # Guiado por watermarks
    HYBRID_AUTO = "hybrid_auto"  # Decisi√≥n autom√°tica inteligente
    CREADO_EL_FILTER = "creado_el_filter"  # üÜï Filtrado directo por creado_el
```

### PASO 2: Agregar m√©todo _build_creado_el_filter_query (despu√©s l√≠nea ~206)
Copiar m√©todo completo desde `raw_data_pipeline_creado_el_query.py`

### PASO 3: Agregar m√©todo extract_table_by_creado_el_range (despu√©s l√≠nea ~735)  
Copiar m√©todo completo desde `raw_data_pipeline_creado_el_single.py`

### PASO 4: Agregar m√©todos m√∫ltiples (despu√©s del paso 3)
Copiar m√©todos desde `raw_data_pipeline_creado_el_multiple.py`:
- `extract_multiple_tables_by_creado_el_range`
- `get_tables_with_creado_el`

## üìñ Ejemplos de Uso Despu√©s de Integraci√≥n

```python
# Obtener pipeline
pipeline = await etl_dependencies.hybrid_raw_pipeline()

# Ver tablas v√°lidas
valid_tables = pipeline.get_tables_with_creado_el()
print(f"Tablas con creado_el: {valid_tables}")  # ['asignaciones', 'trandeuda', 'pagos']

# Extraer una tabla por rango de fechas
result = await pipeline.extract_table_by_creado_el_range(
    "asignaciones", 
    date(2024, 12, 1), 
    date(2024, 12, 31)
)
print(f"Registros cargados: {result.records_loaded}")

# Extraer m√∫ltiples tablas
result = await pipeline.extract_multiple_tables_by_creado_el_range(
    ["asignaciones", "trandeuda"],
    date(2024, 12, 15), 
    date(2024, 12, 21)
)
print(f"Resumen: {result['successful_tables']}")
```

## üîç Validaci√≥n de Integraci√≥n

```python
# Test b√°sico
pipeline = await etl_dependencies.hybrid_raw_pipeline()

# 1. Verificar que el enum tiene la nueva estrategia
assert hasattr(ExtractionStrategy, 'CREADO_EL_FILTER')

# 2. Verificar que los m√©todos existen
assert hasattr(pipeline, '_build_creado_el_filter_query')
assert hasattr(pipeline, 'extract_table_by_creado_el_range') 
assert hasattr(pipeline, 'extract_multiple_tables_by_creado_el_range')
assert hasattr(pipeline, 'get_tables_with_creado_el')

# 3. Verificar tablas v√°lidas
valid_tables = pipeline.get_tables_with_creado_el()
expected_tables = ['asignaciones', 'trandeuda', 'pagos']
assert all(table in valid_tables for table in expected_tables)

print("‚úÖ Integraci√≥n validada correctamente")
```

## üéØ Casos de Uso Principales

### 1. Recuperaci√≥n de Datos
```python
# Recuperar datos perdidos de una fecha espec√≠fica
await pipeline.extract_table_by_creado_el_range(
    "pagos", 
    date(2024, 12, 25), 
    date(2024, 12, 25)  # Un solo d√≠a
)
```

### 2. An√°lisis Ad-hoc
```python
# Extraer datos para an√°lisis sin afectar watermarks
await pipeline.extract_multiple_tables_by_creado_el_range(
    None,  # Todas las tablas
    date(2024, 11, 1), 
    date(2024, 11, 30),
    update_watermarks=False
)
```

### 3. Reprocessing Temporal
```python
# Reprocesar una semana espec√≠fica con todas las tablas
await pipeline.extract_multiple_tables_by_creado_el_range(
    ["asignaciones", "trandeuda", "pagos"],
    date(2024, 12, 10), 
    date(2024, 12, 16),
    include_timestamps=True,
    max_parallel=2
)
```

### 4. Validaci√≥n de Datos
```python
# Verificar integridad de datos en un per√≠odo
result = await pipeline.extract_table_by_creado_el_range(
    "asignaciones",
    date(2024, 12, 1), 
    date(2024, 12, 1),
    include_timestamps=False,
    update_watermark=False  # No afectar watermarks
)

if result.status == "success":
    print(f"Integridad OK: {result.records_loaded} registros encontrados")
```

## ‚ö° Comandos CLI (Para implementaci√≥n futura)

```bash
# Extraer tabla espec√≠fica por rango
python -c "
import asyncio
from datetime import date
from etl.dependencies import etl_dependencies

async def extract_by_date():
    await etl_dependencies.init_resources()
    pipeline = await etl_dependencies.hybrid_raw_pipeline()
    
    result = await pipeline.extract_table_by_creado_el_range(
        'asignaciones', 
        date(2024, 12, 1), 
        date(2024, 12, 31)
    )
    print(f'Loaded: {result.records_loaded} records')
    
    await etl_dependencies.shutdown_resources()

asyncio.run(extract_by_date())
"

# Ver tablas v√°lidas
python -c "
import asyncio
from etl.dependencies import etl_dependencies

async def show_valid_tables():
    await etl_dependencies.init_resources()
    pipeline = await etl_dependencies.hybrid_raw_pipeline()
    
    tables = pipeline.get_tables_with_creado_el()
    print(f'Tablas v√°lidas: {tables}')
    
    await etl_dependencies.shutdown_resources()

asyncio.run(show_valid_tables())
"
```

## üö® Validaciones y Errores Comunes

### Error: Tabla sin creado_el
```python
# Esto fallar√°:
await pipeline.extract_table_by_creado_el_range("ejecutivos", ...)
# Error: Table 'ejecutivos' does not use 'creado_el' as incremental column

# Soluci√≥n: Verificar primero
valid_tables = pipeline.get_tables_with_creado_el()
if "ejecutivos" in valid_tables:
    # OK para extraer
```

### Error: Fechas inv√°lidas
```python
# Esto fallar√°:
await pipeline.extract_table_by_creado_el_range(
    "asignaciones",
    date(2024, 12, 31),  # fin antes que inicio
    date(2024, 12, 1)
)

# Soluci√≥n: Validar fechas
if start_date <= end_date:
    # OK para extraer
```

### Error: Query malformada
```python
# Si el template SQL no tiene {incremental_filter}
# Error: KeyError: 'incremental_filter'

# Verificar que el archivo SQL tenga:
# WHERE creado_el {incremental_filter}
```

## üîß Troubleshooting

### 1. Verificar configuraci√≥n de tabla
```python
from etl.config import ETLConfig
config = ETLConfig.get_config("asignaciones")
print(f"Incremental column: {config.incremental_column}")
# Debe ser: creado_el
```

### 2. Verificar template SQL
```python
pipeline = await etl_dependencies.hybrid_raw_pipeline()
template = pipeline._get_query_template("asignaciones")
print("Placeholders en template:", 
      [p for p in ["incremental_filter", "project_id", "dataset_id", "campaign_archivo"] 
       if f"{{{p}}}" in template])
```

### 3. Test de query building
```python
query = await pipeline._build_creado_el_filter_query(
    "asignaciones", 
    date(2024, 12, 1), 
    date(2024, 12, 31)
)
print("Query generada:")
print(query[:500] + "..." if len(query) > 500 else query)
```

## üìä M√©tricas de Performance

```python
import time
from datetime import date

start_time = time.time()

result = await pipeline.extract_multiple_tables_by_creado_el_range(
    None,  # Todas las tablas
    date(2024, 12, 1), 
    date(2024, 12, 7),  # Una semana
    max_parallel=3
)

end_time = time.time()
duration = end_time - start_time

print(f"‚è±Ô∏è Performance Metrics:")
print(f"   Total duration: {duration:.2f}s")
print(f"   Records loaded: {result['total_records_loaded']:,}")
print(f"   Records/second: {result['total_records_loaded']/duration:.0f}")
print(f"   Successful tables: {len(result['successful_tables'])}")
print(f"   Parallel workers: {result['max_parallel']}")
```

## ‚úÖ Checklist Final

- [ ] ExtractionStrategy.CREADO_EL_FILTER agregado
- [ ] M√©todo _build_creado_el_filter_query integrado
- [ ] M√©todo extract_table_by_creado_el_range integrado
- [ ] M√©todo extract_multiple_tables_by_creado_el_range integrado
- [ ] M√©todo get_tables_with_creado_el integrado
- [ ] Validaci√≥n b√°sica ejecutada
- [ ] Test con una tabla ejecutado
- [ ] Test con m√∫ltiples tablas ejecutado
- [ ] Documentaci√≥n de casos de uso revisada

## üéØ Pr√≥ximos Pasos Opcionales

1. **CLI Command**: Crear comando espec√≠fico en `run_pipeline.py`
2. **Scheduling**: Integrar con sistema de cron/scheduler
3. **Monitoring**: A√±adir m√©tricas y alertas espec√≠ficas
4. **Documentation**: Expandir documentaci√≥n de usuario
5. **Testing**: Crear tests unitarios y de integraci√≥n